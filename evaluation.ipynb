{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f75c5e",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de86222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset Order, you can also evaluate separately and use the corresponding code for evaluation\n",
    "\n",
    "#### semeval2018_english_test,semeval2018_arabic_test,semeval2018_spanish_test,EWECT_usual_test,EWECT_virus_test,onlineshopping_test,MMS_test,XED_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f688e621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>The intensity score for Emotion E (anger) in t...</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>Based on the given text, I would assess the em...</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>The intensity of emotion E in the text can be ...</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>Based on the text provided, the emotion E, whi...</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>The intensity score for emotion E (anger) in t...</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65250</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>{7}. Anticipation</td>\n",
       "      <td>2. sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65251</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>{4}. Fear</td>\n",
       "      <td>4. fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65252</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>{1}. Disgust</td>\n",
       "      <td>2. sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65253</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>{1}. Disgust</td>\n",
       "      <td>2. sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65254</th>\n",
       "      <td>You are a helpful assistant for affective anal...</td>\n",
       "      <td>{3}. Anger</td>\n",
       "      <td>5. surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65255 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "0      You are a helpful assistant for affective anal...   \n",
       "1      You are a helpful assistant for affective anal...   \n",
       "2      You are a helpful assistant for affective anal...   \n",
       "3      You are a helpful assistant for affective anal...   \n",
       "4      You are a helpful assistant for affective anal...   \n",
       "...                                                  ...   \n",
       "65250  You are a helpful assistant for affective anal...   \n",
       "65251  You are a helpful assistant for affective anal...   \n",
       "65252  You are a helpful assistant for affective anal...   \n",
       "65253  You are a helpful assistant for affective anal...   \n",
       "65254  You are a helpful assistant for affective anal...   \n",
       "\n",
       "                                                 predict        label  \n",
       "0      The intensity score for Emotion E (anger) in t...        0.734  \n",
       "1      Based on the given text, I would assess the em...        0.422  \n",
       "2      The intensity of emotion E in the text can be ...        0.663  \n",
       "3      Based on the text provided, the emotion E, whi...        0.703  \n",
       "4      The intensity score for emotion E (anger) in t...        0.719  \n",
       "...                                                  ...          ...  \n",
       "65250                                  {7}. Anticipation   2. sadness  \n",
       "65251                                          {4}. Fear      4. fear  \n",
       "65252                                       {1}. Disgust   2. sadness  \n",
       "65253                                       {1}. Disgust   2. sadness  \n",
       "65254                                         {3}. Anger  5. surprise  \n",
       "\n",
       "[65255 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.tools import *\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "\n",
    "file_path = \"./predicts/texts/generated_predictions.jsonl\"\n",
    "data = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line.strip()))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_semeval2018_english = df[:13269].reset_index(drop=True)\n",
    "df_semeval2018_arabic = df[13269:19373].reset_index(drop=True)\n",
    "df_semeval2018_spanish = df[19373:28755].reset_index(drop=True)\n",
    "EWECT_usual_test = df[28755:33755].reset_index(drop=True)\n",
    "EWECT_virus_test = df[33755:36755].reset_index(drop=True)\n",
    "onlineshopping_test = df[36755:39255].reset_index(drop=True)\n",
    "MMS_test = df[39255:52755].reset_index(drop=True)\n",
    "XED_test = df[52755:65255].reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250ec1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b16f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdea6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_write = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024928d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ef0ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIreg:  ave anger fear joy sadness\n",
      "0.0863936187983066 0.1889495569491233 0.03719642639432761 0.09427879294351836 0.025149698906257185\n",
      "EIreg:  ave anger fear joy sadness\n",
      "0.11368090574128496 0.09179560760422588 0.10615389545331783 0.059704810967509986 0.19706930894008617\n",
      "Voc\n",
      "0.35337451559813143\n",
      "Vreg\n",
      "0.6187461292007865\n",
      "Ec: acc mic-f1 mac-f1\n",
      "0.18851806065659305 0.31202907543657477 0.24646315715136993\n"
     ]
    }
   ],
   "source": [
    "# SemEval_en\n",
    "from sklearn.metrics import f1_score, jaccard_score, accuracy_score\n",
    "\n",
    "df_EIreg = df_semeval2018_english[:4068].reset_index(drop=True)\n",
    "df_EIoc = df_semeval2018_english[4068:8136].reset_index(drop=True)\n",
    "df_Voc = df_semeval2018_english[8136:9073].reset_index(drop=True)\n",
    "df_Vreg = df_semeval2018_english[9073:10010].reset_index(drop=True)\n",
    "df_Ec = df_semeval2018_english[10010:13269].reset_index(drop=True)\n",
    "\n",
    "# EIreg\n",
    "df_EIreg[\"predict_\"] = df_EIreg[\"predict\"].apply(get_scores_EIreg)\n",
    "df_EIreg[\"label_\"] = df_EIreg[\"label\"].apply(get_scores_EIreg)\n",
    "eva_EIreg_anger = df_EIreg[0:1002]\n",
    "eva_EIreg_fear = df_EIreg[1002:1988].reset_index(drop=True)\n",
    "eva_EIreg_joy = df_EIreg[1988:3093].reset_index(drop=True)\n",
    "eva_EIreg_sadness = df_EIreg[3093:4068].reset_index(drop=True)\n",
    "anger_correlation = eva_EIreg_anger['predict_'].corr(eva_EIreg_anger['label_'], method='pearson')\n",
    "fear_correlation = eva_EIreg_fear['predict_'].corr(eva_EIreg_fear['label_'], method='pearson')\n",
    "joy_correlation = eva_EIreg_joy['predict_'].corr(eva_EIreg_joy['label_'], method='pearson')\n",
    "sadness_correlation = eva_EIreg_sadness['predict_'].corr(eva_EIreg_sadness['label_'], method='pearson')\n",
    "ave = np.mean([anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "print(\"EIreg: \",\"ave\",\"anger\",\"fear\",\"joy\",\"sadness\")\n",
    "print(ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation)\n",
    "results_write.extend([ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "\n",
    "# EIoc\n",
    "df_EIoc[\"predict_\"] = df_EIoc[\"predict\"].apply(extract_integers_EIoc)\n",
    "df_EIoc[\"label_\"] = df_EIoc[\"label\"].apply(extract_integers_EIoc)\n",
    "eva_EIoc_anger = df_EIoc[0:1002]\n",
    "eva_EIoc_fear = df_EIoc[1002:1988].reset_index(drop=True)\n",
    "eva_EIoc_joy = df_EIoc[1988:3093].reset_index(drop=True)\n",
    "eva_EIoc_sadness = df_EIoc[3093:4068].reset_index(drop=True)\n",
    "anger_correlation = eva_EIoc_anger['predict_'].corr(eva_EIoc_anger['label_'], method='pearson')\n",
    "fear_correlation = eva_EIoc_fear['predict_'].corr(eva_EIoc_fear['label_'], method='pearson')\n",
    "joy_correlation = eva_EIoc_joy['predict_'].corr(eva_EIoc_joy['label_'], method='pearson')\n",
    "sadness_correlation = eva_EIoc_sadness['predict_'].corr(eva_EIoc_sadness['label_'], method='pearson')\n",
    "ave = np.mean([anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "print(\"EIreg: \",\"ave\",\"anger\",\"fear\",\"joy\",\"sadness\")\n",
    "print(ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation)\n",
    "results_write.extend([ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "\n",
    "\n",
    "# Voc\n",
    "df_Voc[\"predict_\"] = df_Voc[\"predict\"].apply(extract_integers_Voc)\n",
    "df_Voc[\"label_\"] = df_Voc[\"label\"].apply(extract_integers_Voc)\n",
    "correlation = df_Voc['predict_'].corr(df_Voc['label_'], method='pearson')\n",
    "print(\"Voc\")\n",
    "print(correlation)\n",
    "results_write.extend([correlation])\n",
    "\n",
    "# Vreg\n",
    "df_Vreg[\"predict_\"] = df_Vreg[\"predict\"].apply(get_scores_Vreg)\n",
    "df_Vreg[\"label_\"] = df_Vreg[\"label\"].apply(get_scores_Vreg)\n",
    "correlation = df_Vreg['predict_'].corr(df_Vreg['label_'], method='pearson')\n",
    "print(\"Vreg\")\n",
    "print(correlation)\n",
    "results_write.extend([correlation])\n",
    "\n",
    "\n",
    "# Ec\n",
    "df_Ec[\"label_\"] = df_Ec[\"label\"].apply(parse_labels_Ec)\n",
    "df_Ec[\"predict_\"] = df_Ec[\"predict\"].apply(parse_labels_Ec)\n",
    "y_true = np.array(df_Ec[\"label_\"].tolist())\n",
    "y_pred = np.array(df_Ec[\"predict_\"].tolist())\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)  \n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy = jaccard_score(y_true,y_pred, average='weighted')\n",
    "print(\"Ec:\",\"acc\",\"mic-f1\",\"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c60be6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIreg:  ave anger fear joy sadness\n",
      "-0.02431572020536795 -0.03739759246690567 -0.09766690700886374 0.06715358144805039 -0.029351962793752788\n",
      "EIreg:  ave anger fear joy sadness\n",
      "0.022674823541623736 0.06000329487754422 0.02966064469170994 -0.01324945896824079 0.014284813565481573\n",
      "Voc\n",
      "0.24788638378784178\n",
      "Vreg\n",
      "0.3534154041704705\n",
      "Ec: acc mic-f1 mac-f1\n",
      "0.11199856651279064 0.20344894400310015 0.14388365783642576\n"
     ]
    }
   ],
   "source": [
    "# SemEval_ar\n",
    "\n",
    "df_EIreg = df_semeval2018_arabic[:1563].reset_index(drop=True)\n",
    "df_EIoc = df_semeval2018_arabic[1563:3126].reset_index(drop=True)\n",
    "df_Voc = df_semeval2018_arabic[3126:3856].reset_index(drop=True)\n",
    "df_Vreg = df_semeval2018_arabic[3856:4586].reset_index(drop=True)\n",
    "df_Ec = df_semeval2018_arabic[4586:].reset_index(drop=True)\n",
    "\n",
    "# EIreg\n",
    "df_EIreg[\"predict_\"] = df_EIreg[\"predict\"].apply(get_scores_EIreg)\n",
    "df_EIreg[\"label_\"] = df_EIreg[\"label\"].apply(get_scores_EIreg)\n",
    "eva_EIreg_anger = df_EIreg[0:373]\n",
    "eva_EIreg_fear = df_EIreg[373:745].reset_index(drop=True)\n",
    "eva_EIreg_joy = df_EIreg[745:1193].reset_index(drop=True)\n",
    "eva_EIreg_sadness = df_EIreg[1193:1563].reset_index(drop=True)\n",
    "anger_correlation = eva_EIreg_anger['predict_'].corr(eva_EIreg_anger['label_'], method='pearson')\n",
    "fear_correlation = eva_EIreg_fear['predict_'].corr(eva_EIreg_fear['label_'], method='pearson')\n",
    "joy_correlation = eva_EIreg_joy['predict_'].corr(eva_EIreg_joy['label_'], method='pearson')\n",
    "sadness_correlation = eva_EIreg_sadness['predict_'].corr(eva_EIreg_sadness['label_'], method='pearson')\n",
    "ave = np.mean([anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "print(\"EIreg: \",\"ave\",\"anger\",\"fear\",\"joy\",\"sadness\")\n",
    "print(ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation)\n",
    "results_write.extend([ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "\n",
    "# EIoc\n",
    "df_EIoc[\"predict_\"] = df_EIoc[\"predict\"].apply(extract_integers_EIoc)\n",
    "df_EIoc[\"label_\"] = df_EIoc[\"label\"].apply(extract_integers_EIoc)\n",
    "eva_EIoc_anger = df_EIoc[0:373]\n",
    "eva_EIoc_fear = df_EIoc[373:745].reset_index(drop=True)\n",
    "eva_EIoc_joy = df_EIoc[745:1193].reset_index(drop=True)\n",
    "eva_EIoc_sadness = df_EIoc[1193:1563].reset_index(drop=True)\n",
    "anger_correlation = eva_EIoc_anger['predict_'].corr(eva_EIoc_anger['label_'], method='pearson')\n",
    "fear_correlation = eva_EIoc_fear['predict_'].corr(eva_EIoc_fear['label_'], method='pearson')\n",
    "joy_correlation = eva_EIoc_joy['predict_'].corr(eva_EIoc_joy['label_'], method='pearson')\n",
    "sadness_correlation = eva_EIoc_sadness['predict_'].corr(eva_EIoc_sadness['label_'], method='pearson')\n",
    "ave = np.mean([anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "print(\"EIreg: \",\"ave\",\"anger\",\"fear\",\"joy\",\"sadness\")\n",
    "print(ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation)\n",
    "results_write.extend([ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "\n",
    "# Voc\n",
    "df_Voc[\"predict_\"] = df_Voc[\"predict\"].apply(extract_integers_Voc)\n",
    "df_Voc[\"label_\"] = df_Voc[\"label\"].apply(extract_integers_Voc)\n",
    "correlation = df_Voc['predict_'].corr(df_Voc['label_'], method='pearson')\n",
    "print(\"Voc\")\n",
    "print(correlation)\n",
    "results_write.extend([correlation])\n",
    "\n",
    "# Vreg\n",
    "df_Vreg[\"predict_\"] = df_Vreg[\"predict\"].apply(get_scores_Vreg)\n",
    "df_Vreg[\"label_\"] = df_Vreg[\"label\"].apply(get_scores_Vreg)\n",
    "correlation = df_Vreg['predict_'].corr(df_Vreg['label_'], method='pearson')\n",
    "print(\"Vreg\")\n",
    "print(correlation)\n",
    "results_write.extend([correlation])\n",
    "\n",
    "# Ec\n",
    "df_Ec[\"label_\"] = df_Ec[\"label\"].apply(parse_labels_Ec)\n",
    "df_Ec[\"predict_\"] = df_Ec[\"predict\"].apply(parse_labels_Ec)\n",
    "y_true = np.array(df_Ec[\"label_\"].tolist())\n",
    "y_pred = np.array(df_Ec[\"predict_\"].tolist())\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1) \n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy = jaccard_score(y_true,y_pred, average='weighted')\n",
    "print(\"Ec:\",\"acc\",\"mic-f1\",\"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf032c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIreg:  ave anger fear joy sadness\n",
      "0.029362212595999207 0.12142366538495562 -0.05525225530952126 0.12410116977652466 -0.0728237294679622\n",
      "EIreg:  ave anger fear joy sadness\n",
      "0.06666450614385279 0.06498573964489061 0.04900829362119919 0.040406528866702554 0.11225746244261882\n",
      "Voc\n",
      "0.2963341507639899\n",
      "Vreg\n",
      "0.4212872911736552\n",
      "Ec: acc mic-f1 mac-f1\n",
      "0.20092512644182206 0.328622816032888 0.23759532351863866\n"
     ]
    }
   ],
   "source": [
    "# SemEval_spanish\n",
    "\n",
    "df_EIreg = df_semeval2018_spanish[:2616].reset_index(drop=True)\n",
    "df_EIoc = df_semeval2018_spanish[2616:5232].reset_index(drop=True)\n",
    "df_Voc = df_semeval2018_spanish[5232:5880].reset_index(drop=True)\n",
    "df_Vreg = df_semeval2018_spanish[5880:6528].reset_index(drop=True)\n",
    "df_Ec = df_semeval2018_spanish[6528:9382].reset_index(drop=True)\n",
    "\n",
    "# EIreg\n",
    "df_EIreg[\"predict_\"] = df_EIreg[\"predict\"].apply(get_scores_EIreg)\n",
    "df_EIreg[\"label_\"] = df_EIreg[\"label\"].apply(get_scores_EIreg)\n",
    "eva_EIreg_anger = df_EIreg[0:627]\n",
    "eva_EIreg_fear = df_EIreg[627:1245].reset_index(drop=True)\n",
    "eva_EIreg_joy = df_EIreg[1245:1975].reset_index(drop=True)\n",
    "eva_EIreg_sadness = df_EIreg[1975:2616].reset_index(drop=True)\n",
    "anger_correlation = eva_EIreg_anger['predict_'].corr(eva_EIreg_anger['label_'], method='pearson')\n",
    "fear_correlation = eva_EIreg_fear['predict_'].corr(eva_EIreg_fear['label_'], method='pearson')\n",
    "joy_correlation = eva_EIreg_joy['predict_'].corr(eva_EIreg_joy['label_'], method='pearson')\n",
    "sadness_correlation = eva_EIreg_sadness['predict_'].corr(eva_EIreg_sadness['label_'], method='pearson')\n",
    "ave = np.mean([anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "print(\"EIreg: \",\"ave\",\"anger\",\"fear\",\"joy\",\"sadness\")\n",
    "print(ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation)\n",
    "results_write.extend([ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "\n",
    "# EIoc\n",
    "df_EIoc[\"predict_\"] = df_EIoc[\"predict\"].apply(extract_integers_EIoc)\n",
    "df_EIoc[\"label_\"] = df_EIoc[\"label\"].apply(extract_integers_EIoc)\n",
    "eva_EIoc_anger = df_EIoc[0:627]\n",
    "eva_EIoc_fear = df_EIoc[627:1245].reset_index(drop=True)\n",
    "eva_EIoc_joy = df_EIoc[1245:1975].reset_index(drop=True)\n",
    "eva_EIoc_sadness = df_EIoc[1975:2616].reset_index(drop=True)\n",
    "anger_correlation = eva_EIoc_anger['predict_'].corr(eva_EIoc_anger['label_'], method='pearson')\n",
    "fear_correlation = eva_EIoc_fear['predict_'].corr(eva_EIoc_fear['label_'], method='pearson')\n",
    "joy_correlation = eva_EIoc_joy['predict_'].corr(eva_EIoc_joy['label_'], method='pearson')\n",
    "sadness_correlation = eva_EIoc_sadness['predict_'].corr(eva_EIoc_sadness['label_'], method='pearson')\n",
    "ave = np.mean([anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "print(\"EIreg: \",\"ave\",\"anger\",\"fear\",\"joy\",\"sadness\")\n",
    "print(ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation)\n",
    "results_write.extend([ave,anger_correlation,fear_correlation,joy_correlation,sadness_correlation])\n",
    "\n",
    "# Voc\n",
    "df_Voc[\"predict_\"] = df_Voc[\"predict\"].apply(extract_integers_Voc)\n",
    "df_Voc[\"label_\"] = df_Voc[\"label\"].apply(extract_integers_Voc)\n",
    "correlation = df_Voc['predict_'].corr(df_Voc['label_'], method='pearson')\n",
    "print(\"Voc\")\n",
    "print(correlation)\n",
    "results_write.extend([correlation])\n",
    "\n",
    "# Vreg\n",
    "df_Vreg[\"predict_\"] = df_Vreg[\"predict\"].apply(get_scores_Vreg)\n",
    "df_Vreg[\"label_\"] = df_Vreg[\"label\"].apply(get_scores_Vreg)\n",
    "correlation = df_Vreg['predict_'].corr(df_Vreg['label_'], method='pearson')\n",
    "print(\"Vreg\")\n",
    "print(correlation)\n",
    "results_write.extend([correlation])\n",
    "\n",
    "# Ec\n",
    "df_Ec[\"label_\"] = df_Ec[\"label\"].apply(parse_labels_Ec)\n",
    "df_Ec[\"predict_\"] = df_Ec[\"predict\"].apply(parse_labels_Ec)\n",
    "y_true = np.array(df_Ec[\"label_\"].tolist())\n",
    "y_pred = np.array(df_Ec[\"predict_\"].tolist())\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy = jaccard_score(y_true,y_pred, average='weighted')\n",
    "print(\"Ec:\",\"acc\",\"mic-f1\",\"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44e098c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWECT_usual: acc mic-f1 mac-f1\n",
      "0.4262 0.43430017519953285 0.37747380139331965\n",
      "EWECT_virus: acc mic-f1 mac-f1\n",
      "0.4053333333333333 0.4108614837562632 0.298011970376541\n"
     ]
    }
   ],
   "source": [
    "EWECT_usual_test[\"predict_\"] = EWECT_usual_test[\"predict\"].apply(parse_labels_EWECT)\n",
    "EWECT_usual_test[\"label_\"] = EWECT_usual_test[\"label\"].apply(parse_labels_EWECT)\n",
    "y_true = np.array(EWECT_usual_test[\"label_\"].tolist())\n",
    "y_pred = np.array(EWECT_usual_test[\"predict_\"].tolist())\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)  \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"EWECT_usual:\",\"acc\", \"mic-f1\",\"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,macro_f1])\n",
    "\n",
    "EWECT_virus_test[\"predict_\"] = EWECT_virus_test[\"predict\"].apply(parse_labels_EWECT)\n",
    "EWECT_virus_test[\"label_\"] = EWECT_virus_test[\"label\"].apply(parse_labels_EWECT)\n",
    "y_true = np.array(EWECT_virus_test[\"label_\"].tolist())\n",
    "y_pred = np.array(EWECT_virus_test[\"predict_\"].tolist())\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)  \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"EWECT_virus:\",\"acc\", \"mic-f1\",\"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,macro_f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac6fa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onlineshopping: acc mac-f1\n",
      "0.8316 0.5713836082512772\n"
     ]
    }
   ],
   "source": [
    "onlineshopping_test[\"predict_\"] = onlineshopping_test[\"predict\"].apply(extract_label_onlineshopping)\n",
    "onlineshopping_test[\"label_\"] = onlineshopping_test[\"label\"].apply(extract_label_onlineshopping)\n",
    "accuracy = accuracy_score(onlineshopping_test['label_'], onlineshopping_test['predict_'])\n",
    "macro_f1 = f1_score(onlineshopping_test['label_'], onlineshopping_test['predict_'], average='macro')\n",
    "print(\"onlineshopping:\",\"acc\", \"mac-f1\")\n",
    "print(accuracy,macro_f1)\n",
    "results_write.extend([accuracy,macro_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63bb00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMS: acc mac-f1\n",
      "0.4617777777777778 0.3170070257648976\n"
     ]
    }
   ],
   "source": [
    "MMS_test[\"predict_\"] = MMS_test[\"predict\"].apply(extract_label_MMS)\n",
    "MMS_test[\"label_\"] = MMS_test[\"label\"].apply(extract_label_MMS)\n",
    "accuracy = accuracy_score(MMS_test['label_'], MMS_test['predict_'])\n",
    "macro_f1 = f1_score(MMS_test['label_'], MMS_test['predict_'], average='macro')\n",
    "print(\"MMS:\",\"acc\", \"mac-f1\")\n",
    "print(accuracy,macro_f1)\n",
    "results_write.extend([accuracy,macro_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb289b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   language  accuracy  macro_f1\n",
      "0    lang_1     0.376  0.271393\n",
      "1    lang_2     0.430  0.297476\n",
      "2    lang_3     0.452  0.292904\n",
      "3    lang_4     0.600  0.382165\n",
      "4    lang_5     0.486  0.440305\n",
      "5    lang_6     0.690  0.375553\n",
      "6    lang_7     0.540  0.352516\n",
      "7    lang_8     0.396  0.293230\n",
      "8    lang_9     0.516  0.452381\n",
      "9   lang_10     0.414  0.253825\n",
      "10  lang_11     0.472  0.318554\n",
      "11  lang_12     0.562  0.345348\n",
      "12  lang_13     0.558  0.429235\n",
      "13  lang_14     0.432  0.281692\n",
      "14  lang_15     0.490  0.362297\n",
      "15  lang_16     0.370  0.338617\n",
      "16  lang_17     0.472  0.408281\n",
      "17  lang_18     0.378  0.345012\n",
      "18  lang_19     0.472  0.346551\n",
      "19  lang_20     0.562  0.327781\n",
      "20  lang_21     0.386  0.272743\n",
      "21  lang_22     0.470  0.260986\n",
      "22  lang_23     0.322  0.224737\n",
      "23  lang_24     0.436  0.310100\n",
      "24  lang_25     0.276  0.228621\n",
      "25  lang_26     0.378  0.276563\n",
      "26  lang_27     0.532  0.385251\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "num_languages = 27\n",
    "rows_per_language = 500\n",
    "\n",
    "for i in range(num_languages):\n",
    "    start_idx = i * rows_per_language\n",
    "    end_idx = start_idx + rows_per_language\n",
    "    subset = MMS_test.iloc[start_idx:end_idx]\n",
    "    \n",
    "    accuracy = accuracy_score(subset['label_'], subset['predict_'])\n",
    "    macro_f1 = f1_score(subset['label_'], subset['predict_'], average='macro')\n",
    "    \n",
    "    results.append({'language': f'lang_{i+1}', 'accuracy': accuracy, 'macro_f1': macro_f1})\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"./results/MMS_languages.csv\",index=False)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a2d69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"prompt\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe37579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XED: acc mic-f1 mac-f1\n",
      "0.1271803411429323 0.21537853553886974 0.19034426575335456\n"
     ]
    }
   ],
   "source": [
    "XED_test[\"predict_\"] = XED_test[\"predict\"].apply(parse_labels_XED)\n",
    "XED_test[\"label_\"] = XED_test[\"label\"].apply(parse_labels_XED)\n",
    "y_true = np.array(XED_test[\"label_\"].tolist())\n",
    "y_pred = np.array(XED_test[\"predict_\"].tolist())\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)  \n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy = jaccard_score(y_true,y_pred, average='weighted')\n",
    "print(\"XED:\",\"acc\", \"mic-f1\",\"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2138e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XED: acc, mic-f1, mac-f1\n",
      "   language  accuracy  macro_f1  micro_f1\n",
      "0    lang_1  0.145462  0.201600  0.227155\n",
      "1    lang_2  0.112672  0.176896  0.193122\n",
      "2    lang_3  0.127127  0.187975  0.222387\n",
      "3    lang_4  0.115113  0.174191  0.199228\n",
      "4    lang_5  0.131230  0.187952  0.219986\n",
      "5    lang_6  0.132409  0.193529  0.230548\n",
      "6    lang_7  0.121708  0.187838  0.208254\n",
      "7    lang_8  0.207228  0.282119  0.327994\n",
      "8    lang_9  0.150830  0.214325  0.253763\n",
      "9   lang_10  0.103087  0.162577  0.176923\n",
      "10  lang_11  0.142164  0.199003  0.242245\n",
      "11  lang_12  0.108017  0.169126  0.189020\n",
      "12  lang_13  0.119370  0.190382  0.208426\n",
      "13  lang_14  0.119214  0.178224  0.207042\n",
      "14  lang_15  0.140838  0.206997  0.237637\n",
      "15  lang_16  0.121237  0.177542  0.202279\n",
      "16  lang_17  0.116830  0.171325  0.190803\n",
      "17  lang_18  0.110943  0.166386  0.187320\n",
      "18  lang_19  0.151923  0.219991  0.256677\n",
      "19  lang_20  0.116916  0.176982  0.199728\n",
      "20  lang_21  0.138022  0.205870  0.238889\n",
      "21  lang_22  0.119501  0.174044  0.199723\n",
      "22  lang_23  0.099460  0.152509  0.171932\n",
      "23  lang_24  0.128520  0.191866  0.214794\n",
      "24  lang_25  0.104682  0.156322  0.178427\n"
     ]
    }
   ],
   "source": [
    "num_languages = 25\n",
    "rows_per_language = 500\n",
    "results = []\n",
    "for i in range(num_languages):\n",
    "    start_idx = i * rows_per_language\n",
    "    end_idx = start_idx + rows_per_language\n",
    "    subset = XED_test.iloc[start_idx:end_idx]\n",
    "    \n",
    "    y_true = np.array(subset[\"label_\"].tolist())\n",
    "    y_pred = np.array(subset[\"predict_\"].tolist())\n",
    "    \n",
    "#     accuracy = accuracy_score(y_true, y_pred)\n",
    "    accuracy = jaccard_score(y_true,y_pred, average='weighted')\n",
    "    micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
    "    \n",
    "    results.append({\n",
    "        'language': f'lang_{i+1}', \n",
    "        'accuracy': accuracy, \n",
    "        'macro_f1': macro_f1,\n",
    "        'micro_f1': micro_f1 \n",
    "        \n",
    "    })\n",
    "#     break\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"./results/XED_languages.csv\",index=False)\n",
    "print(\"XED: acc, mic-f1, mac-f1\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5528ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to DataFrame\n",
    "df_results_write = pd.DataFrame([results_write])\n",
    "\n",
    "# write to CSV fule\n",
    "df_results_write.to_csv(\"./results/results_text.csv\", index=False, header=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bf0a7",
   "metadata": {},
   "source": [
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd999abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset Order, you can also evaluate separately and use the corresponding code for evaluation\n",
    "#### EMOTIC_EC_test,EMOTIC_SI_test,FER2013_test,CFAPS_EC_test,CFAPS_EI_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7049d785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>18. engagement</td>\n",
       "      <td>1. happiness, 8. peace, 9. affection, 12. conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>1. happiness, 18. engagement</td>\n",
       "      <td>1. happiness, 7. excitement, 8. peace, 13. dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>1. happiness</td>\n",
       "      <td>7. excitement, 11. anticipation, 14. disconnec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>1. happiness, 22. pleasure</td>\n",
       "      <td>1. happiness, 8. peace, 12. confidence, 22. pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>1. happiness</td>\n",
       "      <td>1. happiness, 7. excitement, 8. peace, 11. ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21927</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.707894736842105</td>\n",
       "      <td>0.7604166666666663\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21928</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>0.5548780487804875\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21929</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.630434782608695</td>\n",
       "      <td>0.5885416666666663\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21930</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.601190476190475\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21931</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.509375\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21932 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "0      <|im_start|>system\\nYou are a helpful assistan...   \n",
       "1      <|im_start|>system\\nYou are a helpful assistan...   \n",
       "2      <|im_start|>system\\nYou are a helpful assistan...   \n",
       "3      <|im_start|>system\\nYou are a helpful assistan...   \n",
       "4      <|im_start|>system\\nYou are a helpful assistan...   \n",
       "...                                                  ...   \n",
       "21927  <|im_start|>system\\nYou are a helpful assistan...   \n",
       "21928  <|im_start|>system\\nYou are a helpful assistan...   \n",
       "21929  <|im_start|>system\\nYou are a helpful assistan...   \n",
       "21930  <|im_start|>system\\nYou are a helpful assistan...   \n",
       "21931  <|im_start|>system\\nYou are a helpful assistan...   \n",
       "\n",
       "                            predict  \\\n",
       "0                    18. engagement   \n",
       "1      1. happiness, 18. engagement   \n",
       "2                      1. happiness   \n",
       "3        1. happiness, 22. pleasure   \n",
       "4                      1. happiness   \n",
       "...                             ...   \n",
       "21927             0.707894736842105   \n",
       "21928                       0.59375   \n",
       "21929             0.630434782608695   \n",
       "21930                      0.578125   \n",
       "21931                           0.5   \n",
       "\n",
       "                                                   label  \n",
       "0      1. happiness, 8. peace, 9. affection, 12. conf...  \n",
       "1      1. happiness, 7. excitement, 8. peace, 13. dis...  \n",
       "2      7. excitement, 11. anticipation, 14. disconnec...  \n",
       "3      1. happiness, 8. peace, 12. confidence, 22. pl...  \n",
       "4      1. happiness, 7. excitement, 8. peace, 11. ant...  \n",
       "...                                                  ...  \n",
       "21927                               0.7604166666666663\\n  \n",
       "21928                               0.5548780487804875\\n  \n",
       "21929                               0.5885416666666663\\n  \n",
       "21930                                0.601190476190475\\n  \n",
       "21931                                         0.509375\\n  \n",
       "\n",
       "[21932 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.tools import *\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file_path = \"./predicts/images/generated_predictions.jsonl\"\n",
    "data = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line.strip()))\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "EMOTIC_seg_emo_test = df[:7203].reset_index(drop=True)\n",
    "EMOTIC_seg_sentiment_test = df[7203:14406].reset_index(drop=True)\n",
    "FER2013_test = df[14406:21584].reset_index(drop=True)\n",
    "CFAPS_emo_test = df[21584:21758].reset_index(drop=True)\n",
    "CFAPS_emoint_test = df[21758:21932].reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad49f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.5578125</td>\n",
       "      <td>0.460843373493975\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.677195945945945</td>\n",
       "      <td>0.7927215189873412\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.60546875</td>\n",
       "      <td>0.6021341463414625\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.6470588235294113</td>\n",
       "      <td>0.7938311688311688\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.46774193548387</td>\n",
       "      <td>0.5460526315789462\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.707894736842105</td>\n",
       "      <td>0.7604166666666663\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>0.5548780487804875\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.630434782608695</td>\n",
       "      <td>0.5885416666666663\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.601190476190475\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.509375\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt             predict  \\\n",
       "0    <|im_start|>system\\nYou are a helpful assistan...           0.5578125   \n",
       "1    <|im_start|>system\\nYou are a helpful assistan...   0.677195945945945   \n",
       "2    <|im_start|>system\\nYou are a helpful assistan...          0.60546875   \n",
       "3    <|im_start|>system\\nYou are a helpful assistan...  0.6470588235294113   \n",
       "4    <|im_start|>system\\nYou are a helpful assistan...    0.46774193548387   \n",
       "..                                                 ...                 ...   \n",
       "169  <|im_start|>system\\nYou are a helpful assistan...   0.707894736842105   \n",
       "170  <|im_start|>system\\nYou are a helpful assistan...             0.59375   \n",
       "171  <|im_start|>system\\nYou are a helpful assistan...   0.630434782608695   \n",
       "172  <|im_start|>system\\nYou are a helpful assistan...            0.578125   \n",
       "173  <|im_start|>system\\nYou are a helpful assistan...                 0.5   \n",
       "\n",
       "                    label  \n",
       "0     0.460843373493975\\n  \n",
       "1    0.7927215189873412\\n  \n",
       "2    0.6021341463414625\\n  \n",
       "3    0.7938311688311688\\n  \n",
       "4    0.5460526315789462\\n  \n",
       "..                    ...  \n",
       "169  0.7604166666666663\\n  \n",
       "170  0.5548780487804875\\n  \n",
       "171  0.5885416666666663\\n  \n",
       "172   0.601190476190475\\n  \n",
       "173            0.509375\\n  \n",
       "\n",
       "[174 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFAPS_emoint_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3516a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_write = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6e526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lzw/packages/anaconda3/envs/ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in labels with no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTIC_emo: acc mic-f1 mac-f1\n",
      "0.2269986218933977 0.38002218685187866 0.18972664472831802\n",
      "EMOTIC_vad: V A D\n",
      "0.47801115958052764 0.5355533270486557 0.2356522709128337\n",
      "FER2013: acc mic-f1 mac-f1\n",
      "0.553496795764837 0.553496795764837 0.4595078967261605\n",
      "CFAPS_emo: acc mic-f1 mac-f1\n",
      "0.8908045977011494 0.8908045977011495 0.8281739515166481\n",
      "CFAPS_emoint\n",
      "0.8430492204522055\n"
     ]
    }
   ],
   "source": [
    "EMOTIC_seg_emo_test[\"predict_\"] = EMOTIC_seg_emo_test[\"predict\"].apply(parse_labels_EMOTIC_emo)\n",
    "EMOTIC_seg_emo_test[\"label_\"] = EMOTIC_seg_emo_test[\"label\"].apply(parse_labels_EMOTIC_emo)\n",
    "y_true = np.array(EMOTIC_seg_emo_test[\"label_\"].tolist())\n",
    "y_pred = np.array(EMOTIC_seg_emo_test[\"predict_\"].tolist())\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)  \n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy = jaccard_score(y_true,y_pred, average='weighted')\n",
    "print(\"EMOTIC_emo:\",\"acc\", \"mic-f1\", \"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n",
    "\n",
    "EMOTIC_seg_sentiment_test[['predict_valence', 'predict_arousal', 'predict_dominance']] = EMOTIC_seg_sentiment_test['predict'].apply(lambda x: pd.Series(extract_values_EMOTIC_vad(x)))\n",
    "EMOTIC_seg_sentiment_test[['label_valence', 'label_arousal', 'label_dominance']] = EMOTIC_seg_sentiment_test['label'].apply(lambda x: pd.Series(extract_values_EMOTIC_vad(x)))\n",
    "\n",
    "valence_corr = calculate_pearson_correlation(EMOTIC_seg_sentiment_test['predict_valence'], EMOTIC_seg_sentiment_test['label_valence'])\n",
    "arousal_corr = calculate_pearson_correlation(EMOTIC_seg_sentiment_test['predict_arousal'], EMOTIC_seg_sentiment_test['label_arousal'])\n",
    "dominance_corr = calculate_pearson_correlation(EMOTIC_seg_sentiment_test['predict_dominance'], EMOTIC_seg_sentiment_test['label_dominance'])\n",
    "\n",
    "print(\"EMOTIC_vad:\",\"V\",\"A\",\"D\")\n",
    "print(valence_corr,arousal_corr,dominance_corr)\n",
    "results_write.extend([valence_corr,arousal_corr,dominance_corr])\n",
    "\n",
    "FER2013_test[\"predict_\"] = FER2013_test[\"predict\"].apply(parse_labels_FER2013)\n",
    "FER2013_test[\"label_\"] = FER2013_test[\"label\"].apply(parse_labels_FER2013)\n",
    "y_true = np.array(FER2013_test[\"label_\"].tolist())\n",
    "y_pred = np.array(FER2013_test[\"predict_\"].tolist())\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)  \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"FER2013:\",\"acc\", \"mic-f1\", \"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,macro_f1])\n",
    "\n",
    "CFAPS_emo_test[\"predict_\"] = CFAPS_emo_test[\"predict\"].apply(parse_labels_CFAPS_emo)\n",
    "CFAPS_emo_test[\"label_\"] = CFAPS_emo_test[\"label\"].apply(parse_labels_CFAPS_emo)\n",
    "y_true = np.array(CFAPS_emo_test[\"label_\"].tolist())\n",
    "y_pred = np.array(CFAPS_emo_test[\"predict_\"].tolist())\n",
    "micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)  \n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"CFAPS_emo:\",\"acc\", \"mic-f1\", \"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,macro_f1])\n",
    "\n",
    "\n",
    "CFAPS_emoint_test[\"predict_\"] = CFAPS_emoint_test[\"predict\"].apply(get_scores_CFAPS_emoint)\n",
    "CFAPS_emoint_test[\"label_\"] = CFAPS_emoint_test[\"label\"].apply(get_scores_CFAPS_emoint)\n",
    "\n",
    "correlation = CFAPS_emoint_test['predict_'].corr(CFAPS_emoint_test['label_'], method='pearson')\n",
    "print(\"CFAPS_emoint\")\n",
    "print(correlation)\n",
    "results_write.extend([correlation])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0219dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "      <th>predict_</th>\n",
       "      <th>label_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.5578125</td>\n",
       "      <td>0.460843373493975\\n</td>\n",
       "      <td>0.557813</td>\n",
       "      <td>0.460843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.677195945945945</td>\n",
       "      <td>0.7927215189873412\\n</td>\n",
       "      <td>0.677196</td>\n",
       "      <td>0.792722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.60546875</td>\n",
       "      <td>0.6021341463414625\\n</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.602134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.6470588235294113</td>\n",
       "      <td>0.7938311688311688\\n</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.793831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.46774193548387</td>\n",
       "      <td>0.5460526315789462\\n</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.546053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.707894736842105</td>\n",
       "      <td>0.7604166666666663\\n</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.760417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>0.5548780487804875\\n</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.554878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.630434782608695</td>\n",
       "      <td>0.5885416666666663\\n</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.588542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.601190476190475\\n</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.601190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.509375\\n</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.509375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt             predict  \\\n",
       "0    <|im_start|>system\\nYou are a helpful assistan...           0.5578125   \n",
       "1    <|im_start|>system\\nYou are a helpful assistan...   0.677195945945945   \n",
       "2    <|im_start|>system\\nYou are a helpful assistan...          0.60546875   \n",
       "3    <|im_start|>system\\nYou are a helpful assistan...  0.6470588235294113   \n",
       "4    <|im_start|>system\\nYou are a helpful assistan...    0.46774193548387   \n",
       "..                                                 ...                 ...   \n",
       "169  <|im_start|>system\\nYou are a helpful assistan...   0.707894736842105   \n",
       "170  <|im_start|>system\\nYou are a helpful assistan...             0.59375   \n",
       "171  <|im_start|>system\\nYou are a helpful assistan...   0.630434782608695   \n",
       "172  <|im_start|>system\\nYou are a helpful assistan...            0.578125   \n",
       "173  <|im_start|>system\\nYou are a helpful assistan...                 0.5   \n",
       "\n",
       "                    label  predict_    label_  \n",
       "0     0.460843373493975\\n  0.557813  0.460843  \n",
       "1    0.7927215189873412\\n  0.677196  0.792722  \n",
       "2    0.6021341463414625\\n  0.605469  0.602134  \n",
       "3    0.7938311688311688\\n  0.647059  0.793831  \n",
       "4    0.5460526315789462\\n  0.467742  0.546053  \n",
       "..                    ...       ...       ...  \n",
       "169  0.7604166666666663\\n  0.707895  0.760417  \n",
       "170  0.5548780487804875\\n  0.593750  0.554878  \n",
       "171  0.5885416666666663\\n  0.630435  0.588542  \n",
       "172   0.601190476190475\\n  0.578125  0.601190  \n",
       "173            0.509375\\n  0.500000  0.509375  \n",
       "\n",
       "[174 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFAPS_emoint_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0820f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_write = pd.DataFrame([results_write])\n",
    "df_results_write.to_csv(\"./results/results_image.csv\", index=False, header=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d96765",
   "metadata": {},
   "source": [
    "# video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a81b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset Order, you can also evaluate separately and use the corresponding code for evaluation\n",
    "\n",
    "#### SAMSEMO_test,MELD_EC_test,MELD_SP_test,CHSIMS_SP_test,CHSIMS_SI_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b80dba26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0. neutral</td>\n",
       "      <td>5. surprise\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0. neutral</td>\n",
       "      <td>0. neutral\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>0. neutral</td>\n",
       "      <td>0. neutral\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>1. happiness</td>\n",
       "      <td>1. happiness\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>1. happiness</td>\n",
       "      <td>1. happiness\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8151</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.2\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8152</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8153</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8154</th>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou are a helpful assistan...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8155 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt       predict  \\\n",
       "0     <|im_start|>system\\nYou are a helpful assistan...    0. neutral   \n",
       "1     <|im_start|>system\\nYou are a helpful assistan...    0. neutral   \n",
       "2     <|im_start|>system\\nYou are a helpful assistan...    0. neutral   \n",
       "3     <|im_start|>system\\nYou are a helpful assistan...  1. happiness   \n",
       "4     <|im_start|>system\\nYou are a helpful assistan...  1. happiness   \n",
       "...                                                 ...           ...   \n",
       "8150  <|im_start|>system\\nYou are a helpful assistan...          -0.4   \n",
       "8151  <|im_start|>system\\nYou are a helpful assistan...          -0.8   \n",
       "8152  <|im_start|>system\\nYou are a helpful assistan...          -1.0   \n",
       "8153  <|im_start|>system\\nYou are a helpful assistan...          -1.0   \n",
       "8154  <|im_start|>system\\nYou are a helpful assistan...          -1.0   \n",
       "\n",
       "               label  \n",
       "0      5. surprise\\n  \n",
       "1       0. neutral\\n  \n",
       "2       0. neutral\\n  \n",
       "3     1. happiness\\n  \n",
       "4     1. happiness\\n  \n",
       "...              ...  \n",
       "8150          -1.0\\n  \n",
       "8151          -0.2\\n  \n",
       "8152          -1.0\\n  \n",
       "8153          -1.0\\n  \n",
       "8154          -1.0\\n  \n",
       "\n",
       "[8155 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.tools import *\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file_path = \"./predicts/videos/generated_predictions.jsonl\" \n",
    "data = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line.strip()))\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "SAMSEMO_test = df[:2181].reset_index(drop=True)\n",
    "MELD_emo_test = df[2181:4711].reset_index(drop=True)\n",
    "MELD_Sentiment_test = df[4711:7241].reset_index(drop=True)\n",
    "CHSIMS_polarity_test = df[7241:7698].reset_index(drop=True)\n",
    "CHSIMS_strength_test = df[7698:8155].reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6190bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94aebc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_write = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182b5588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMSEMO_macro 0.513624592151392 0.674937965260546 0.5124364143850584\n",
      "SAMSEMO_DE 0.43995908405167017 0.6116373477672531 0.5109276449746007\n",
      "SAMSEMO_EN 0.4927058569278302 0.6627318718381112 0.6070522620884977\n",
      "SAMSEMO_ES 0.49999269151212616 0.669051878354204 0.44977053915275994\n",
      "SAMSEMO_KO 0.5235368059539747 0.6719999999999999 0.5732867415070806\n",
      "SAMSEMO_PL 0.5790291450731813 0.7163029525032093 0.4309102670898862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xb/mtrqllcj6wv_x2vxx75t3t400000gn/T/ipykernel_19662/4058833317.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merage_text[\"transcript\"] = merage_text[\"transcript\"].apply(rmpunctuation)\n",
      "/Users/lzw/packages/anaconda3/envs/ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in labels with no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lzw/packages/anaconda3/envs/ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in labels with no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lzw/packages/anaconda3/envs/ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in labels with no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lzw/packages/anaconda3/envs/ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in labels with no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lzw/packages/anaconda3/envs/ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in labels with no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lzw/packages/anaconda3/envs/ai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in labels with no true or predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "SAMSEMO_test[\"predict_\"] = SAMSEMO_test[\"predict\"].apply(parse_labels_SAMSEMO)\n",
    "SAMSEMO_test[\"label_\"] = SAMSEMO_test[\"label\"].apply(parse_labels_SAMSEMO)\n",
    "\n",
    "def rmpunctuation(text):\n",
    "    return ''.join(char for char in text if char not in string.punctuation)\n",
    "\n",
    "def extract_content(text):\n",
    "    clean_text = re.sub(r'<\\|.*?\\|>', '', text) \n",
    "    match = re.search(r'Content: (.*)', clean_text)\n",
    "    if match:\n",
    "        return match.group(1)  \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def extract_content(text):\n",
    "    clean_text = re.sub(r'<\\|.*?\\|>', '', text)  \n",
    "    match = re.search(r'Content: (.*)', clean_text)\n",
    "    if match:\n",
    "        return match.group(1).replace(\" ASSISTANT:\",\"\")  \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "SAMSEMO_original = pd.read_csv(\"./video/Sansemo/test.csv\")\n",
    "SAMSEMO_test[\"text\"] = SAMSEMO_test[\"prompt\"].apply(extract_content)\n",
    "SAMSEMO_test[\"text\"] = SAMSEMO_test[\"text\"].apply(rmpunctuation)\n",
    "merage_text = SAMSEMO_original[[\"transcript\",\"labels\",\"language\"]]\n",
    "merage_text[\"transcript\"] = merage_text[\"transcript\"].apply(rmpunctuation)\n",
    "merged = pd.merge(SAMSEMO_test, merage_text, left_on='text', right_on='transcript', how='left')\n",
    "\n",
    "merged[\"predict_\"] = merged[\"predict\"].apply(parse_labels_SAMSEMO)\n",
    "merged[\"label_\"] = merged[\"label\"].apply(parse_labels_SAMSEMO)\n",
    "\n",
    "\n",
    "SAMSEMO_DE = merged[merged[\"language\"]==\"DE\"]\n",
    "SAMSEMO_EN = merged[merged[\"language\"]==\"EN\"]\n",
    "SAMSEMO_ES = merged[merged[\"language\"]==\"ES\"]\n",
    "SAMSEMO_KO = merged[merged[\"language\"]==\"KO\"]\n",
    "SAMSEMO_PL = merged[merged[\"language\"]==\"PL\"]\n",
    "\n",
    "y_true = np.array(merged[\"label_\"].tolist())\n",
    "y_pred = np.array(merged[\"predict_\"].tolist())\n",
    "accuracy,micro_f1,macro_f1 = get_ACCandF1(y_true, y_pred)\n",
    "print(\"SAMSEMO_macro\", accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n",
    "\n",
    "y_true = np.array(SAMSEMO_DE[\"label_\"].tolist())\n",
    "y_pred = np.array(SAMSEMO_DE[\"predict_\"].tolist())\n",
    "accuracy,micro_f1,macro_f1 = get_ACCandF1(y_true, y_pred)\n",
    "print(\"SAMSEMO_DE\", accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n",
    "\n",
    "y_true = np.array(SAMSEMO_EN[\"label_\"].tolist())\n",
    "y_pred = np.array(SAMSEMO_EN[\"predict_\"].tolist())\n",
    "accuracy,micro_f1,macro_f1 = get_ACCandF1(y_true, y_pred)\n",
    "print(\"SAMSEMO_EN\", accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n",
    "\n",
    "y_true = np.array(SAMSEMO_ES[\"label_\"].tolist())\n",
    "y_pred = np.array(SAMSEMO_ES[\"predict_\"].tolist())\n",
    "accuracy,micro_f1,macro_f1 = get_ACCandF1(y_true, y_pred)\n",
    "print(\"SAMSEMO_ES\", accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n",
    "\n",
    "y_true = np.array(SAMSEMO_KO[\"label_\"].tolist())\n",
    "y_pred = np.array(SAMSEMO_KO[\"predict_\"].tolist())\n",
    "accuracy,micro_f1,macro_f1 = get_ACCandF1(y_true, y_pred)\n",
    "print(\"SAMSEMO_KO\", accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n",
    "\n",
    "y_true = np.array(SAMSEMO_PL[\"label_\"].tolist())\n",
    "y_pred = np.array(SAMSEMO_PL[\"predict_\"].tolist())\n",
    "accuracy,micro_f1,macro_f1 = get_ACCandF1(y_true, y_pred)\n",
    "print(\"SAMSEMO_PL\", accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,micro_f1,macro_f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8339eac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MELD_emo: acc mic-f1 mac-f1\n",
      "0.47105899917335337 0.6296442687747036 0.469303636341926\n",
      "MELD_sen: acc mac-f1\n",
      "0.7090909090909091 0.6848621287144622\n",
      "CHSIMS_sen: acc mac-f1\n",
      "0.7221006564551422 0.6347286519723683\n",
      "CHSIMS_strength\n",
      "0.6747855302501787\n"
     ]
    }
   ],
   "source": [
    "MELD_emo_test[\"predict_\"] = MELD_emo_test[\"predict\"].apply(parse_labels_MELD_emo)\n",
    "MELD_emo_test[\"label_\"] = MELD_emo_test[\"label\"].apply(parse_labels_MELD_emo)\n",
    "y_true = np.array(MELD_emo_test[\"label_\"].tolist())\n",
    "y_pred = np.array(MELD_emo_test[\"predict_\"].tolist())\n",
    "accuracy,micro_f1,macro_f1 = get_ACCandF1(y_true, y_pred)\n",
    "print(\"MELD_emo:\",\"acc\", \"mic-f1\", \"mac-f1\")\n",
    "print(accuracy,micro_f1,macro_f1)\n",
    "results_write.extend([accuracy,macro_f1])\n",
    "\n",
    "MELD_Sentiment_test[\"predict_\"] = MELD_Sentiment_test[\"predict\"].apply(extract_label_MELD_sen)\n",
    "MELD_Sentiment_test[\"label_\"] = MELD_Sentiment_test[\"label\"].apply(extract_label_MELD_sen)\n",
    "accuracy = accuracy_score(MELD_Sentiment_test['label_'], MELD_Sentiment_test['predict_'])\n",
    "macro_f1 = f1_score(MELD_Sentiment_test['label_'], MELD_Sentiment_test['predict_'], average='macro')\n",
    "print(\"MELD_sen:\",\"acc\", \"mac-f1\")\n",
    "print(accuracy,macro_f1)\n",
    "results_write.extend([accuracy,macro_f1])\n",
    "\n",
    "CHSIMS_polarity_test[\"predict_\"] = CHSIMS_polarity_test[\"predict\"].apply(extract_label_CHSIMS_pol)\n",
    "CHSIMS_polarity_test[\"label_\"] = CHSIMS_polarity_test[\"label\"].apply(extract_label_CHSIMS_pol)\n",
    "accuracy = accuracy_score(CHSIMS_polarity_test['label_'], CHSIMS_polarity_test['predict_'])\n",
    "macro_f1 = f1_score(CHSIMS_polarity_test['label_'], CHSIMS_polarity_test['predict_'], average='macro')\n",
    "print(\"CHSIMS_sen:\",\"acc\", \"mac-f1\")\n",
    "print(accuracy,macro_f1)\n",
    "results_write.extend([accuracy,macro_f1])\n",
    "\n",
    "CHSIMS_strength_test[\"predict_\"] = CHSIMS_strength_test[\"predict\"].apply(get_scores_CHSIMS_strength)\n",
    "CHSIMS_strength_test[\"label_\"] = CHSIMS_strength_test[\"label\"].apply(get_scores_CHSIMS_strength)\n",
    "correlation = CHSIMS_strength_test['predict_'].corr(CHSIMS_strength_test['label_'], method='pearson')\n",
    "print(\"CHSIMS_strength\")\n",
    "print(correlation)\n",
    "results_write.extend([correlation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7997d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_write = pd.DataFrame([results_write])\n",
    "df_results_write.to_csv(\"./results/results_video.csv\", index=False, header=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd29e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
